{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bb93373",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "\n",
    "This full example is meant to implement how the digital twin abstract class is supposed to be useful and work. It will show what needs to be done on the model end as well as what gets used on the digital twin abstract class end.\n",
    "\n",
    "The directory for this model is \"model2\"\n",
    "\n",
    "Everything here would be what should be going into a dt.py file that would create the digital twin framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a2d981",
   "metadata": {},
   "source": [
    "# 1. Data Pipelines\n",
    "\n",
    "# Model Specific\n",
    "\n",
    "## Types\n",
    "\n",
    "Under types, there is definitions for all types that are to be used in the system. Copious typing should be done, and for all data types with both raw/processed there should be a type.\n",
    "\n",
    "## Data\n",
    "\n",
    "While there is data processing functions, these are supposed to be light data functions and any hardcode data processing should be through a data infrastructure. The functions will be of the following categories, where N is a variable number of data pulls, and brackets will show how many of any given type there should be.\n",
    "\n",
    "1. [1+] Data Connection Method: A method for how to connect to the database. Input: None Output: Connection\n",
    "2. [N] Raw Data Pulls: Pulls that directly hit the data infrastructure held database tables. Input: Connection Output: Raw Data Type\n",
    "3. [N] Data Processing: Any light data processing such as doing pivots since holding a pivot table would be space ineffecient on the SQL side. Input: Raw Data Type Output: Processed Data Type\n",
    "4. [1] Backtest Data Pull: A pull that combines all raw pulls and data processing pulls, plus connects to the database and returns a Backtest Data Type. Input: None Output: Backtest Data Type\n",
    "5. [1] Input Data Computation: A processing function that takes backtest data and then returns starting state, the historical data, the input data (what goes into the backtest) and the output data (what is being used to validate the backtest). Input: Backtest Data Type Output: Input Data Type\n",
    "6. [1] Format Inputs: One function which takes the input data and formats the input into data classes for use within cadCAD.\n",
    "\n",
    "# Digital Twin Specific\n",
    "\n",
    "1. A DataPipeline class should be made which fills out pull_historical_data, compute_input_data, format_input_data corresponding to the functions defined above.\n",
    "2. A function of load_data_initial should be made in the DT class which specifies how to save down pulled data. This can be csv, pickle, etc. \n",
    "3. A function of load_data_prior should be made in the DT class which specifies how to pull back old data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12002370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import digital_twin\n",
    "from model2.data import pull_backtest_data, create_input_data, format_inputs\n",
    "from model2.types import BacktestData\n",
    "\n",
    "class ArbitrageDataPipeline(digital_twin.DataPipeline):\n",
    "    \n",
    "    def pull_historical_data(self):\n",
    "        return pull_backtest_data()\n",
    "    \n",
    "    def compute_input_data(self, data):\n",
    "        return create_input_data(data)\n",
    "    \n",
    "    def format_input_data(self, data):\n",
    "        return format_inputs(data)\n",
    "\n",
    "class ArbitrageDigitalTwin(digital_twin.DigitalTwin):\n",
    "    \n",
    "    def load_data_initial(self):\n",
    "        self.historical_data = self.data_pipeline.pull_historical_data()\n",
    "        \n",
    "        self.historical_data.pure_returns.to_csv(\"pure_returns.csv\")\n",
    "        self.historical_data.prices_data.to_csv(\"prices_data.csv\")\n",
    "        self.historical_data.trades_data.to_csv(\"trades_data.csv\")\n",
    "    \n",
    "    def load_data_prior(self):\n",
    "        pure_returns = pd.read_csv(\"pure_returns.csv\", index_col = 0)\n",
    "        prices_data = pd.read_csv(\"prices_data.csv\", index_col = 0)\n",
    "        trades_data = pd.read_csv(\"trades_data.csv\", index_col = 0)\n",
    "        \n",
    "        self.historical_data = BacktestData(pure_returns = pure_returns_data, \n",
    "                        prices_data = prices_data,\n",
    "                        trades_data = trades_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b4a546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestDataPipeline = ArbitrageDataPipeline()\n",
    "arb_dt = ArbitrageDigitalTwin(name = \"Test\",\n",
    "                    data_pipeline = TestDataPipeline)\n",
    "arb_dt.load_data_initial()\n",
    "arb_dt.compute_input_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc842ace",
   "metadata": {},
   "source": [
    "# 2. Backtest Model\n",
    "\n",
    "# Model Specific\n",
    "\n",
    "## Partial State Update Blocks\n",
    "\n",
    "- The file of psub.py holds all the partial state update blocks. There is distinction between the backtesting based blocks and the extrapolation based blocks.\n",
    "\n",
    "## Run \n",
    "\n",
    "This file has a few functionalities to be built.\n",
    "\n",
    "1. load_config_backtest: This function is meant to load up the configuration for backtesting.\n",
    "2. run: A function for running the model\n",
    "3. post_processing: A function for post processing after the run\n",
    "\n",
    "# Digital Twin Specific\n",
    "\n",
    "1. A BacktestModel class needs to be made from digital twin model\n",
    "2. The load config function should map the configuration loading for backtesting\n",
    "3. The run model function fills in how the model will run\n",
    "4. Post processing likewise is mapped through there\n",
    "\n",
    "We add it into the full workflow below as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b488ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model2.run import load_config_backtest, run, post_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "505f3042",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BacktestModel(digital_twin.Model):\n",
    "    def load_config(self, monte_carlo_runs, timesteps,\n",
    "                    params, initial_state):\n",
    "        exp = load_config_backtest(monte_carlo_runs = monte_carlo_runs,\n",
    "            timesteps = timesteps,\n",
    "            params = params,\n",
    "            initial_state = initial_state)\n",
    "        return exp\n",
    "    \n",
    "    def run_model(self, exp):\n",
    "        raw = run(exp)\n",
    "        return raw\n",
    "    \n",
    "    def post_processing(self, backtest_data):\n",
    "        df = post_processing(backtest_data)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00085f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  ___________    ____\n",
      "  ________ __ ___/ / ____/   |  / __ \\\n",
      " / ___/ __` / __  / /   / /| | / / / /\n",
      "/ /__/ /_/ / /_/ / /___/ ___ |/ /_/ /\n",
      "\\___/\\__,_/\\__,_/\\____/_/  |_/_____/\n",
      "by cadCAD\n",
      "\n",
      "cadCAD Version: 0.4.28\n",
      "Execution Mode: local_proc\n",
      "Simulation Dimensions:\n",
      "Entire Simulation: (Models, Unique Timesteps, Params, Total Runs, Sub-States) = (1, 100, 1, 1, 2)\n",
      "     Simulation 0: (Timesteps, Params, Runs, Sub-States) = (100, 1, 1, 2)\n",
      "Execution Method: local_simulations\n",
      "Execution Mode: single_threaded\n",
      "Total execution time: 0.05s\n"
     ]
    }
   ],
   "source": [
    "TestDataPipeline = ArbitrageDataPipeline()\n",
    "TestBacktestModel = BacktestModel()\n",
    "arb_dt = ArbitrageDigitalTwin(name = \"Test\",\n",
    "                    data_pipeline = TestDataPipeline,\n",
    "                    backtest_model = TestBacktestModel)\n",
    "arb_dt.load_data_initial()\n",
    "arb_dt.compute_input_data()\n",
    "\n",
    "params_backtest = {}\n",
    "monte_carlo_runs_backtest = 1\n",
    "\n",
    "arb_dt.run_backtest(monte_carlo_runs_backtest, params_backtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9121610",
   "metadata": {},
   "source": [
    "Params can be dynamic to allow for different assumptions about what randomness looks like. For example, one set of params might be \n",
    "\n",
    "The name is for the name to be given to each series of data. The use_seeds param is whether to use seeds 1...N for setting randomness for reproducibility. The param_values are for the values in parameter setting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77777215",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestStochasticFit(digital_twin.StochasticFit):\n",
    "    \n",
    "    def fit_index_return(self, param_value, input_data, historical_data):\n",
    "        if param_value['type'] == 'Expert Model':\n",
    "            #Already has values put in\n",
    "            pass\n",
    "        elif param_value['type'] == 'Normal Fitted':\n",
    "            #Add mu and std\n",
    "            data = historical_data.pure_returns[\"index_return\"]\n",
    "            param_value[\"mu\"] = data.mean()\n",
    "            param_value[\"std\"] = data.std()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "    def fit_basket_return(self, param_value, input_data, historical_data):\n",
    "        if param_value['type'] == 'Expert Model':\n",
    "            #Already has values put in\n",
    "            pass\n",
    "        elif param_value['type'] == 'Normal Fitted':\n",
    "            #Add mu and std\n",
    "            data = historical_data.pure_returns[\"basket_return\"]\n",
    "            param_value[\"mu\"] = data.mean()\n",
    "            param_value[\"std\"] = data.std()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "    def fit_param(self, param, input_data, historical_data):\n",
    "        for pv in param[\"param_values\"]:\n",
    "            if pv == \"index_return\":\n",
    "                self.fit_index_return(param[\"param_values\"][pv], input_data, historical_data)\n",
    "            elif pv == \"basket_return\":\n",
    "                self.fit_basket_return(param[\"param_values\"][pv], input_data, historical_data)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2577bfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  ___________    ____\n",
      "  ________ __ ___/ / ____/   |  / __ \\\n",
      " / ___/ __` / __  / /   / /| | / / / /\n",
      "/ /__/ /_/ / /_/ / /___/ ___ |/ /_/ /\n",
      "\\___/\\__,_/\\__,_/\\____/_/  |_/_____/\n",
      "by cadCAD\n",
      "\n",
      "cadCAD Version: 0.4.28\n",
      "Execution Mode: local_proc\n",
      "Simulation Dimensions:\n",
      "Entire Simulation: (Models, Unique Timesteps, Params, Total Runs, Sub-States) = (1, 100, 1, 1, 2)\n",
      "     Simulation 0: (Timesteps, Params, Runs, Sub-States) = (100, 1, 1, 2)\n",
      "Execution Method: local_simulations\n",
      "Execution Mode: single_threaded\n",
      "Total execution time: 0.03s\n"
     ]
    }
   ],
   "source": [
    "TestDataPipeline = ArbitrageDataPipeline()\n",
    "TestBacktestModel = BacktestModel()\n",
    "\n",
    "params1 = {\"name\": \"Normal Distribution\",\n",
    "           \"monte_carlo_runs\": 10,\n",
    "           \"use_seeds\": True,\n",
    "    \"param_values\": {\"index_return\": {\"type\": \"Normal Fitted\"},\n",
    "         \"basket_return\": {\"type\": \"Normal Fitted\"}}}\n",
    "\n",
    "params2 = {\"name\": \"Expert Model\",\n",
    "           \"monte_carlo_runs\": 10,\n",
    "           \"use_seeds\": True,\n",
    "           \"param_values\": {\"index_return\": {\"type\": \"Expert Model\",\n",
    "                                             \"lambda\": .9,\n",
    "                          \"mu\": .015,\n",
    "                          \"std\": .1},\n",
    "                            \n",
    "         \"basket_return\": {\"type\": \"Expert Model\",\n",
    "                          \"mu\": .01,\n",
    "                           \"std\": .05}}}\n",
    "\n",
    "params_sf = [params1, params2]\n",
    "test_stochastic_fit = TestStochasticFit(params_sf)\n",
    "\n",
    "arb_dt = ArbitrageDigitalTwin(name = \"Test\",\n",
    "                    data_pipeline = TestDataPipeline,\n",
    "                    backtest_model = TestBacktestModel,\n",
    "                    stochastic_fit = test_stochastic_fit)\n",
    "arb_dt.load_data_initial()\n",
    "arb_dt.compute_input_data()\n",
    "\n",
    "params_backtest = {}\n",
    "monte_carlo_runs_backtest = 1\n",
    "\n",
    "\n",
    "arb_dt.run_backtest(monte_carlo_runs_backtest, params_backtest)\n",
    "arb_dt.fit_stochastic_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd734198",
   "metadata": {},
   "source": [
    "# Signal Extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae5b4689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bee764e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from model2.types import Returns\n",
    "\n",
    "class TestSignalExtrapolation(digital_twin.SignalExtrapolation):\n",
    "    def extrapolate_index_return(self, param, t, n, signals):\n",
    "        if param['type'] == 'Expert Model':\n",
    "            signals[\"index_return\"] = param[\"lambda\"] * signals[\"basket_return\"] +\\\n",
    "            (1 - param[\"lambda\"]) * np.random.normal(param[\"mu\"], param[\"std\"], (n, t))\n",
    "        elif param['type'] == 'Normal Fitted':\n",
    "            signals[\"index_return\"] = np.random.normal(param[\"mu\"], param[\"std\"], (n, t))\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    \n",
    "    def extrapolate_basket_return(self, param, t, n, signals):\n",
    "        if param['type'] == 'Expert Model':\n",
    "            signals[\"basket_return\"] = np.random.normal(param[\"mu\"], param[\"std\"], (n, t))\n",
    "        elif param['type'] == 'Normal Fitted':\n",
    "            signals[\"basket_return\"] = np.random.normal(param[\"mu\"], param[\"std\"], (n, t))\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    \n",
    "    def extrapolate_signals(self, stochastic_params, t):\n",
    "        signals_total = []\n",
    "        for stochastic_param_i in stochastic_params:\n",
    "            n = stochastic_param_i[\"monte_carlo_runs\"]\n",
    "            signals = {}\n",
    "            if stochastic_param_i[\"use_seeds\"]:\n",
    "                np.random.seed(1)\n",
    "            self.extrapolate_basket_return(stochastic_param_i[\"param_values\"][\"basket_return\"], t, n, signals)\n",
    "            self.extrapolate_index_return(stochastic_param_i[\"param_values\"][\"index_return\"], t, n, signals)\n",
    "            signals_total.append(signals)\n",
    "        return signals_total\n",
    "    \n",
    "    def process_signal(self, param, signal_raw):\n",
    "        signal = []\n",
    "        for i in range(param[\"monte_carlo_runs\"]):\n",
    "            signal_i = []\n",
    "            br = signal_raw[\"basket_return\"][:,i]\n",
    "            ir = signal_raw[\"index_return\"][:,i]\n",
    "            run_n = i\n",
    "            signal_name = param[\"name\"]\n",
    "            for br_i, ir_i in zip(br, ir):\n",
    "                r = Returns(index_return = ir_i,\n",
    "                           benchmark_return = br_i)\n",
    "                signal_i.append({\"returns\": r,\n",
    "                                \"signal_name\": signal_name,\n",
    "                                \"signal_run_number\": run_n})\n",
    "            signal.append(signal_i)\n",
    "        return signal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27d79735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  ___________    ____\n",
      "  ________ __ ___/ / ____/   |  / __ \\\n",
      " / ___/ __` / __  / /   / /| | / / / /\n",
      "/ /__/ /_/ / /_/ / /___/ ___ |/ /_/ /\n",
      "\\___/\\__,_/\\__,_/\\____/_/  |_/_____/\n",
      "by cadCAD\n",
      "\n",
      "cadCAD Version: 0.4.28\n",
      "Execution Mode: local_proc\n",
      "Simulation Dimensions:\n",
      "Entire Simulation: (Models, Unique Timesteps, Params, Total Runs, Sub-States) = (1, 100, 1, 1, 2)\n",
      "     Simulation 0: (Timesteps, Params, Runs, Sub-States) = (100, 1, 1, 2)\n",
      "Execution Method: local_simulations\n",
      "Execution Mode: single_threaded\n",
      "Total execution time: 0.01s\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'benchmark_return'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5597cfbad495>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0marb_dt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_backtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonte_carlo_runs_backtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_backtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0marb_dt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_stochastic_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0marb_dt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextrapolate_signals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/BlockScience/DTWC/digital_twin/main.py\u001b[0m in \u001b[0;36mextrapolate_signals\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextrapolate_signals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignals_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal_extrapolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextrapolate_signals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_fit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextrapolation_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_signals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_fit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignals_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_extrapolation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mextrapolation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextrapolation_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistorical_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/BlockScience/DTWC/digital_twin/main.py\u001b[0m in \u001b[0;36mprocess_signals\u001b[0;34m(self, params, signals_raw)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0msignals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignals_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0msignals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal_extrapolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msignals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-3898214a55ee>\u001b[0m in \u001b[0;36mprocess_signal\u001b[0;34m(self, param, signal_raw)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0msignal_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbr_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mir_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 r = Returns(index_return = ir_i,\n\u001b[0m\u001b[1;32m     44\u001b[0m                            benchmark_return = br_i)\n\u001b[1;32m     45\u001b[0m                 signal_i.append({\"returns\": r,\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'benchmark_return'"
     ]
    }
   ],
   "source": [
    "TestDataPipeline = ArbitrageDataPipeline()\n",
    "TestBacktestModel = BacktestModel()\n",
    "\n",
    "params1 = {\"name\": \"Normal Distribution\",\n",
    "           \"monte_carlo_runs\": 10,\n",
    "           \"use_seeds\": True,\n",
    "    \"param_values\": {\"index_return\": {\"type\": \"Normal Fitted\"},\n",
    "         \"basket_return\": {\"type\": \"Normal Fitted\"}}}\n",
    "\n",
    "params2 = {\"name\": \"Expert Model\",\n",
    "           \"monte_carlo_runs\": 10,\n",
    "           \"use_seeds\": True,\n",
    "           \"param_values\": {\"index_return\": {\"type\": \"Expert Model\",\n",
    "                                             \"lambda\": .9,\n",
    "                          \"mu\": .015,\n",
    "                          \"std\": .1},\n",
    "                            \n",
    "         \"basket_return\": {\"type\": \"Expert Model\",\n",
    "                          \"mu\": .01,\n",
    "                           \"std\": .05}}}\n",
    "\n",
    "extrapolation_epochs = 25\n",
    "\n",
    "params_sf = [params1, params2]\n",
    "test_stochastic_fit = TestStochasticFit(params_sf)\n",
    "test_signal_extrapolation = TestSignalExtrapolation()\n",
    "\n",
    "arb_dt = ArbitrageDigitalTwin(name = \"Test\",\n",
    "                    data_pipeline = TestDataPipeline,\n",
    "                    backtest_model = TestBacktestModel,\n",
    "                    stochastic_fit = test_stochastic_fit,\n",
    "                    signal_extrapolation = test_signal_extrapolation,\n",
    "                    extrapolation_epochs = extrapolation_epochs)\n",
    "arb_dt.load_data_initial()\n",
    "arb_dt.compute_input_data()\n",
    "\n",
    "params_backtest = {}\n",
    "monte_carlo_runs_backtest = 1\n",
    "\n",
    "\n",
    "arb_dt.run_backtest(monte_carlo_runs_backtest, params_backtest)\n",
    "arb_dt.fit_stochastic_fit()\n",
    "arb_dt.extrapolate_signals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657b1cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bad2e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For extrapolation, convert to the input data, but also add in the name\n",
    "# And an integer for the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cbf78d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to inputs as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56b72a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Returns(index_return=0.10871386253910743, bask...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Returns(index_return=0.015029483765100592, bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Returns(index_return=0.04183835929990093, bask...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Returns(index_return=0.12103416104564571, bask...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Returns(index_return=0.08280887550560694, bask...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Returns(index_return=0.040580329256415186, bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Returns(index_return=0.018690406444573593, bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Returns(index_return=0.0990992137653999, baske...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Returns(index_return=0.037843403664469796, bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Returns(index_return=0.041954800849375494, bas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              returns\n",
       "t                                                    \n",
       "0   Returns(index_return=0.10871386253910743, bask...\n",
       "1   Returns(index_return=0.015029483765100592, bas...\n",
       "2   Returns(index_return=0.04183835929990093, bask...\n",
       "3   Returns(index_return=0.12103416104564571, bask...\n",
       "4   Returns(index_return=0.08280887550560694, bask...\n",
       "..                                                ...\n",
       "95  Returns(index_return=0.040580329256415186, bas...\n",
       "96  Returns(index_return=0.018690406444573593, bas...\n",
       "97  Returns(index_return=0.0990992137653999, baske...\n",
       "98  Returns(index_return=0.037843403664469796, bas...\n",
       "99  Returns(index_return=0.041954800849375494, bas...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arb_dt.input_data.input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a503be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
